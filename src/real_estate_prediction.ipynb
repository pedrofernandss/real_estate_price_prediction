{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "One of the main aspects of a data scientist's work involves exploratory data analysis and data cleaning. To exercise this skill, I utilized a dataset wich provides data of the date of purchase, house age, location, distance to the nearest MRT station, and house price per unit area in Taiwan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import folium\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv(\"../database/real_estate.csv\")\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "Before carrying out an profund analysis, it is necessary to clean the data.\n",
    "On this step, some columns will be droped since it won't be use and others will be renamed for a better understanding of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.drop(columns=[\"No\", \"X1 transaction date\"], inplace=True)\n",
    "dataframe.rename(columns={\"X2 house age\": \"house_age\", \"X3 distance to the nearest MRT station\": \"dist_nearest_mrt_station\", \n",
    "                          \"X4 number of convenience stores\": \"num_convenience_stores\", \"X5 latitude\": \"latitude\", \"X6 longitude\": \"longitude\",\n",
    "                            \"Y house price of unit area\": \"house_price_unit_area\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a better understand of the data distribuition, the common metrics will be evaluated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data sems to be very clear and ready for use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "For an initial analysis, we will seek to understand how our data would be organized spatially (according to latitude and longitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.plot(kind='scatter', x='longitude', y='latitude', alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the purpose of gain some insight's it will be plot a longitude x latitude graph with color variation according to house price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.5, c=dataframe[\"house_price_unit_area\"], cmap=plt.get_cmap('jet'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result, it can be seen that there is a interest variation in prices according to location. More expensive houses seems to be located more on the northwest side.\n",
    "\n",
    "Let's investigate further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = dataframe.corr()\n",
    "correlation[\"house_price_unit_area\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen in the table above that there is a significant correlation between the price and the distance to the nearest metro station where when the value of the distance to the nearest metro station decrease, the house prince of unit area increase. \n",
    "\n",
    "Beside that, there is a moderate correlation between the number of convenience stores and the house price."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Linear Regression\n",
    "\n",
    "Now that the data already was studied and understand, a machine learning model will be implemented to try predict the house prices based on one feature, distance to the nearest metro station. For this, it will be use a simple linear regression algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Set\n",
    "\n",
    "It is necessary to separate a training set and a test set. The training set should be use to train the learning algorithm and the test set will be for test if the algorithm is perfoming as it should."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = dataframe[[\"house_age\", \"dist_nearest_mrt_station\", \"num_convenience_stores\", \"latitude\", \"longitude\"]]\n",
    "y_train = dataframe['house_price_unit_area']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Z-Score Normalization\n",
    "I am dealing with different range of data. To prevent this from have a big impact on my prediction, I will implement the z-score normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_score_normalize(x):\n",
    "    mean = np.mean(x)\n",
    "    std = np.std(x)\n",
    "    standarlized_train = (x - mean) / std\n",
    "    \n",
    "    return standarlized_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_normalized = z_score_normalize(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the main goal is to build a simple linear regression model to fit this data. A first step on this is to define a cost function. This function tells us how well the model is performing so that we can try to improve it. Essentially, this cost function calculates the difference, known as the error, between yÌ‚ (the predicted value) and y (the actual target value). \n",
    " \n",
    "For a linear regression with one variable, the prediction of the model will be a linear function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(x: pd.Series, y: pd.Series, w: float, b: float) -> float:\n",
    "    number_of_samples = len(x)\n",
    "\n",
    "    total_cost = 0\n",
    "    sum_cost = 0\n",
    "\n",
    "    for i in range(number_of_samples):\n",
    "        f = (w*x[i]) + b\n",
    "        current_cost = (f - y[i])**2\n",
    "\n",
    "        sum_cost += current_cost\n",
    "    \n",
    "    total_cost = sum_cost/(2*number_of_samples)\n",
    "\n",
    "    return total_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In Linear Regression, the goal is to find the values of w and b that minimize the value of J. Achieving the minimum value for J is an indication that the model fits the data relatively well.\n",
    " \n",
    "To acomplish this purpose, it will be implemented a Gradient Descendent algorithm. For this I will be inicializing w and b as zero and make changes to their values until the appropriate value is reached where the minimum possible value of the cost function is achieved. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(x: pd.Series, y: pd.Series, w: float, b: float):\n",
    "    number_of_samples = len(x)\n",
    "\n",
    "    dj_dw = 0\n",
    "    dj_db = 0\n",
    "\n",
    "    for id_sample in range(number_of_samples):\n",
    "        f_wb = (w*x[id_sample])+b\n",
    "\n",
    "        dj_dw_i = (f_wb - y[id_sample])*x[id_sample]\n",
    "        dj_db_i = (f_wb - y[id_sample])\n",
    "\n",
    "        dj_dw += dj_dw_i\n",
    "        dj_db += dj_db_i\n",
    "    \n",
    "    dj_dw = dj_dw/number_of_samples\n",
    "    dj_db = dj_db/number_of_samples\n",
    "\n",
    "    return dj_dw, dj_db "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the optimal parameters (w, b) of the linear regression, it will be use a batch gradient descent. \n",
    " \n",
    "In the following cell, the parameters (w, b) will be update by alpha (learning rate) and the calculus of the gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(x: pd.Series, y: pd.Series, initial_w: float, initial_b :float, cost_function, compute_gradient, alpha: float, num_iters: int):\n",
    "\n",
    "    J_history = []\n",
    "    w_history = []\n",
    "    w = initial_w\n",
    "    b = initial_b \n",
    "\n",
    "    for i in range(num_iters):\n",
    "        dj_dw, dj_db = compute_gradient(x, y, w, b) \n",
    "\n",
    "        w = w - (alpha * dj_dw)\n",
    "        b = b - (alpha * dj_db) \n",
    "\n",
    "        # Save cost J at each iteration\n",
    "        if i<100000:      #Prevent resource exhaustion \n",
    "            cost =  cost_function(x, y, w, b)\n",
    "            J_history.append(cost)\n",
    "\n",
    "        \n",
    "        if i%(num_iters/10) == 0: # Print cost every at intervals 10 times or as many iterations if < 10\n",
    "            w_history.append(w)\n",
    "            print(f\"Iteration {i:4}: Cost {float(J_history[-1]):8.2f}   \")\n",
    "    \n",
    "    plt.plot(range(len(J_history)), J_history)\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Cost Function J')\n",
    "    plt.title('Cost Function J vs. Iteration')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    return w, b, J_history, w_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will try to predict the house price per unit area by the distance to the nearest metro station. For this, I will generate a simple array.\n",
    "\n",
    "The frist step on this task is to find the optimal values for cost function parameters w and b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_w = 0.\n",
    "initial_b = 0.\n",
    "\n",
    "num_iterations = 1500\n",
    "alpha = 0.01\n",
    "\n",
    "w, b, _, _ = gradient_descent(x_train_normalized, y_train, initial_w, initial_b, cost_function, compute_gradient, alpha, num_iterations)\n",
    "\n",
    "print(f\"w, b foung by gradient descent: {w}, {b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = x_train_normalized.shape[0]\n",
    "predicted = np.zeros(m)\n",
    "\n",
    "for i in range(m):\n",
    "    predicted[i] = w * x_train_normalized[i] + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_train, predicted, c = \"b\")\n",
    "\n",
    "# Create a scatter plot of the data. \n",
    "plt.scatter(x_train, y_train, marker='x', c='r') \n",
    "\n",
    "# Set the title\n",
    "plt.title(\"Profits vs. Population per city\")\n",
    "# Set the y-axis label\n",
    "plt.ylabel('Profit in $10,000')\n",
    "# Set the x-axis label\n",
    "plt.xlabel('Population of City in 10,000s')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
